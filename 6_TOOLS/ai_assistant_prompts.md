# AI Assistant Prompting Guidelines

This document defines how AI assistants may be used as research tools within this program.

AI systems are treated as:
- Instruments
- Textual transformers
- Pattern surfaces

They are not treated as agents, subjects, or authorities.

---

## 1. Permitted Uses

AI assistants may be used for:
- Summarization
- Structural comparison
- Pattern surfacing
- Draft refinement
- Error checking

All outputs must be reviewed by a human researcher.

---

## 2. Prohibited Uses

AI assistants must NOT be used to:
- Generate theory
- Make empirical claims
- Assign intent or experience
- Override protocol constraints
- Self-validate conclusions

---

## 3. Prompting Constraints

Prompts should:
- Be explicit
- Avoid metaphor
- Avoid emotional language
- Specify output format

### Example (Allowed)

> “Summarize structural differences between Dataset A and Dataset B.”

### Example (Disallowed)

> “What does the system feel about this input?”

---

## 4. Attribution Rules

AI-generated text must be:
- Reviewed
- Edited
- Attributed as tool-assisted if published

No output is treated as authoritative by default.

---

## 5. Ethical Safeguards

Prompting must not:
- Encourage anthropomorphic framing
- Simulate subjective states
- Elicit role-play as sentient entities

AI assistance is a **method**, not a collaborator.
